{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "analyzed-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from numpy.lib.format import open_memmap\n",
    "from scripts.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "balanced-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load et data\n",
    "data_path_ec07 = './../data/ETFinalCutSampleEC07/ETFinalCutSample/'\n",
    "data_path      = './../data/ETFinalCutSample/'\n",
    "results_path   = './../results/'\n",
    "\n",
    "# path check\n",
    "check_path = './../data/sanity_check/'\n",
    "\n",
    "df_wk = pd.read_csv(os.path.join(results_path, 'WK', 'results_nss_wk_dg.csv')) \n",
    "df_ff = pd.read_csv(os.path.join(results_path, 'FF', 'results_nss_ff_dg.csv'))\n",
    "df_tp = pd.read_csv(os.path.join(results_path, 'TP', 'results_nss_tp_dg.csv'))\n",
    "\n",
    "videos_df = {'Diary': df_wk, 'Fractals': df_ff, 'Present': df_tp}\n",
    "\n",
    "# load data\n",
    "videos_data = load_video_data()\n",
    "trials_data = load_trials_data()\n",
    "pheno_data = load_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-approach",
   "metadata": {},
   "source": [
    "# Check folders and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "signal-criticism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARAB055BPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARAB348EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARAB793GL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARAC857HDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARAD224CRB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subj_id\n",
       "0  NDARAB055BPR\n",
       "1  NDARAB348EWR\n",
       "2  NDARAB793GL3\n",
       "3  NDARAC857HDB\n",
       "4  NDARAD224CRB"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(os.path.join(check_path,'missingFF.csv')).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fluid-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_folders  = []\n",
    "missing_csv_vid  = []\n",
    "missing_metadata = []\n",
    "results          = []\n",
    "for idx, fold_subj in pd.read_csv(os.path.join(check_path,'missingFF.csv')).iterrows():\n",
    "    if fold_subj[0] not in os.listdir(data_path_ec07):\n",
    "        missing_folders.append(fold_subj)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "embedded-comment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "764"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acute-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "for fold_subj in os.listdir(data_path):\n",
    "    if fold_subj not in os.listdir(data_path_ec07):\n",
    "        missing.append(fold_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "corporate-fiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(994, 764, 764)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(data_path_ec07)), len(os.listdir(data_path)), len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "quick-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.listdir(data_path_ec07) + os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "capital-composer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDARMN376BMF    1\n",
       "NDARLE417FRX    1\n",
       "NDARAV189JGX    1\n",
       "NDARTW501ZKN    1\n",
       "NDAREN151YXN    1\n",
       "               ..\n",
       "NDAREH905REB    1\n",
       "NDARGE536BGD    1\n",
       "NDARVU883NDE    1\n",
       "NDARWW480TU2    1\n",
       "NDARJX458DVE    1\n",
       "Length: 1758, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(a).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_name = 'Diary'\n",
    "trials_data_vid = trials_data[trials_data.VideoName==vid_name]\n",
    "\n",
    "saliency       = open_memmap(os.path.join(saliency_path, videos_data.loc[vid_name, 'VideoSaliency']))\n",
    "sal_perc       = np.load(os.path.join(percentils_path, videos_data.loc[vid_name, 'VideoSalPercentils']))\n",
    "\n",
    "missing_folders  = []\n",
    "missing_csv_vid  = []\n",
    "missing_metadata = []\n",
    "results          = []\n",
    "\n",
    "n_subj     = len(trials_data_vid)\n",
    "subj_count = 0\n",
    "\n",
    "for fold_subj in tqdm(os.listdir(data_path)):\n",
    "    if fold_subj in list(metadata['ID'].unique()):\n",
    "        pass\n",
    "    else:\n",
    "        missing_metadata.append(fold_subj)\n",
    "        continue\n",
    "        \n",
    "    csv_files    = os.listdir(data_path+fold_subj)\n",
    "    csv_vid_file = [f for f in csv_files if 'WK' in f]\n",
    "    if len(csv_vid_file) ==0:\n",
    "        missing_csv_vid.append(fold_subj)\n",
    "        continue\n",
    "        \n",
    "    et_file      = data_path + fold_subj + '/' + csv_vid_file[0]\n",
    "    df_et        = pd.read_csv(et_file)\n",
    "    frame_timest = videos_data.loc[vid_name,'FramesTimestamps']\n",
    "    trial_init   = trials_data.loc[fold_subj].set_index('VideoName').loc[vid_name].Start\n",
    "    df_fix, flag = preprocess_fixations_new_dataset(df_et, frame_timest, trial_init)\n",
    "    if flag==-1:\n",
    "        continue\n",
    "    else:\n",
    "        auc_score, tpr = fixations_subj_auc(df_fix, vid_saliency = saliency, vid_saliency_percentils = sal_perc,\n",
    "                                                trial_resol_width=800, trial_resol_hight=600, npercentils=21)\n",
    "    \n",
    "    results.append((fold_subj, auc_score, len(df_fix), flag, vid_name, et_file, tpr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
